import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


# ------------------ Load data from the CSV file
train_data = pd.read_csv('cleaned_train_data.csv')
test_data = pd.read_csv('normalized_test_data.csv')


# ------------------ let's consider columns 'Column1' and 'Column2'
column1 = 'input21'
column2 = 'output'


# ------------------ Extract the data for the selected columns
X_train = train_data[column1].values.reshape(-1, 1) #or use [[]] and delete reshape
y_train = train_data[column2].values


# ------------------ Select data for testing
X_test = test_data[column1].values.reshape(-1, 1)
y_test = test_data[column2].values


# ------------------ Train the linear regression model
# Create a Linear Regression model
model = LinearRegression()

# Fit the model
model.fit(X_train, y_train)

# Get the coefficients (slope and intercept)
slope = model.coef_[0]
intercept = model.intercept_

print('Slope: ', slope)
print('Intercept: ', intercept)


# ------------------- Calculate the correlation coefficient
##correlation = model.score(X_train, y_train)


# -------------------- Predict using the trained model
y_pred = model.predict(X_test)


# -------------------- Change of slope and intercept
slopes = [slope-0.1, slope, slope+0.1]
intercepts = [intercept-0.15, intercept, intercept+0.15]


# ------------------ Create a .csv file to save the results
a = open(f'LR_grid search_{column1} vs {column2}.csv','w')
a.write(f'{column1},and,{column2}\n\n Slope,Intercept,MSE,RMSE,STD\n')

for i, slo in enumerate(slopes):
    for j, cep in enumerate(intercepts):

        y_Line = slo * X_test + cep ##(x_train)

        # -------------------- Evaluation (Error)
        # Calculate the Mean Squared Error
        mse = mean_squared_error(y_test, y_Line) ##(y_test, y_pred)
        a.write('%f,%f,%f,'%(slo,cep,mse))

        # Calculate the Root Mean Squared Error
        rmse = mean_squared_error(y_test, y_Line, squared=False)
        a.write('%f,'%rmse)

        # Calculate R-squared(coefficient of determination)
        r2 = r2_score(y_test, y_Line) ##(y_pred)

        print(f"Mean Squared Error: {mse}")
        print(f"R-squared: {r2}")

        # Calculate residuals
        residuals = y_test - y_Line

        # Calculate standard deviation of residuals
        std_deviation = np.std(residuals)
        a.write('%f\n'%std_deviation)


        # -------------------- Create a new figure for each iteration
        plt.figure()  # Create a new figure for each polynomial degree plot


        # -------------------- Create the scatter plot
        plt.scatter(X_train, y_train, label='Data points')
        ##plt.title('Linear Regression')
        plt.xlabel(column1)
        plt.ylabel(column2)


        # -------------------- Plotting the linear regression line
        colors = ['orange', 'red', 'pink']
        #(x_train)
        plt.plot(X_test, y_Line, color=colors[i], label='Linear Regression Line')

        # Displaying correlation value on the plot
        plt.text(0.05, 0.95, f'Slope = {slo:.3f}\n'
                 + f'Intercept = {cep:.3f}',
                 ha='left', va='center',
                 transform=plt.gca().transAxes, fontsize=10)

        # Show legend
        plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.11),
                  fancybox=True, shadow=True, ncol=5)

        props = dict(boxstyle='round', facecolor='red', alpha=0.15)
        # Displaying Error values on the plot
        plt.text(0.85, -0.1,
                 f'MSE = {mse:.3f} / std ={std_deviation:.3f}',
                 verticalalignment='top', horizontalalignment='center',
                 transform=plt.gca().transAxes,
                 bbox = props, fontsize=10)

        # save the plot
        plt.savefig(f'LR_S{i+1}T{j+1}_{column1} vs {column2}.png', dpi=150,
                    bbox_inches='tight')

    # Show the plot
##    plt.show()
a.close()


 
